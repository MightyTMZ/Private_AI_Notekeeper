{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Notekeeper\n",
    "\n",
    "In this use case, we will guide you the steps of storing your notes in various document types and using Ollama to process them. \n",
    "\n",
    "Whether your notes contain sensitive information or not, your data never leaves your device. \n",
    "\n",
    "This project will enable you to ask questions about their vast amounts of notes, PDFs, articles, meeting summaries in a private environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the key advantages of using Ollama is its ability to process large datasets locally without the need for cloud infrastructure or storage limitations. Unlike other platforms that may impose restrictions on the size of data you can work with, Ollama allows you to handle and process as much data as your local system can support. This is particularly useful when working with large volumes of files like PDFs, DOCX documents, MP3s, and more. While the processing time may take longer depending on the size of your data and the resources available on your local machine, the ability to run everything privately and offline is a significant benefit for those who need to keep their data secure and maintain control over their resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install the required libraries and pull the required models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download required Python libraries via PIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!pip install chromadb pandas PyPDF2 openai-whisper python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Ollama CLI, pull the model of `mxbai-embed-large` for generating embeddings and a model of your choice for generating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "ollama pull mxbai-embed-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer\n",
    "\n",
    "While this project demonstrates the power of local AI processing, itâ€™s important to note that **model and dataset sizes can be quite large**, potentially exceeding the capacity of a standard local machine (e.g., 16GB RAM). For optimal performance when working with larger models and datasets, access to a machine with a **powerful GPU and at least 64GB of RAM** is recommended.\n",
    "\n",
    "If you're experimenting with this project on a smaller setup, consider using models like **1B, 3B, 7B, or 16B parameters**, which strike a good balance between capability and resource requirements. Avoid attempting to use excessively large models unless you have access to the necessary hardware. This approach ensures the process remains practical and accessible for demonstration and educational purposes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, we will use the Llama3.1 model with 8B parameters since it only uses 4.9GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "ollama pull llama3.1:8b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define function for file processing\n",
    "\n",
    "We need to define several functions to process different types of files such as PDF, TXT, DOCX, MP3/MP4, and Excel files. These functions will extract the text content from the files, which will later be used to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PyPDF2 import PdfReader\n",
    "import whisper\n",
    "import docx\n",
    "import ollama\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def process_pdf(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from PDF files.\n",
    "    This function uses PyPDF2 to read the content of the PDF file and extracts the text from each page.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(file_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process TXT Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_txt(file_path):\n",
    "    \"\"\"\n",
    "    Reads and returns text from TXT files.\n",
    "    This function simply opens a TXT file and returns its content as a string.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process DOCX Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "\n",
    "def process_docx(file_path):\n",
    "    \"\"\"\n",
    "    Extracts text from DOCX files.\n",
    "    This function uses the docx library to open the DOCX file and retrieves all the text from the document.\n",
    "    \"\"\"\n",
    "    doc = docx.Document(file_path)\n",
    "    return \" \".join([para.text for para in doc.paragraphs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process video and audio files (MP3/MP4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "def transcribe_audio(file_path, model=\"base\"):\n",
    "    '''\n",
    "    Leverages OpenAI's whisper model to transcribe text from videos\n",
    "    '''\n",
    "    audio_model = whisper.load_model(model)\n",
    "    result = audio_model.transcribe(file_path)\n",
    "    return result['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Excel (XLS/XLSX) files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def process_excel(file_path):\n",
    "    '''\n",
    "    Uses Pandas library to process XLS/XLSX files\n",
    "    '''\n",
    "    df = pd.read_excel(file_path)\n",
    "    return df.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile all methods into a single \"preprocess\" function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path):\n",
    "    ext = file_path.split('.')[-1].lower()\n",
    "    if ext == \"pdf\":\n",
    "        return process_pdf(file_path)\n",
    "    elif ext == \"txt\":\n",
    "        return process_txt(file_path)\n",
    "    elif ext in [\"doc\", \"docx\"]:\n",
    "        return process_docx(file_path)\n",
    "    elif ext in [\"mp3\", \"mp4\"]:\n",
    "        return transcribe_audio(file_path)\n",
    "    elif ext in [\"xls\", \"xlsx\"]:\n",
    "        return process_excel(file_path)\n",
    "    else:\n",
    "        return \"Unsupported file type\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Add your data to a folder named \"notes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure the notebook you are running is the in the same level as the notes folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "outputs": [],
   "source": [
    "Personal_Private_Chatbot_using_Ollama.ipynb\n",
    "notes/\n",
    "|--- file1.pdf\n",
    "|--- file2.docx\n",
    "|--- audio1.mp3\n",
    "|--- spreadsheet1.xlsx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Connect to ChromaDB and Create a Collection\n",
    "\n",
    "We use ChromaDB to store and query document embeddings. Let's initialize the client and create a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "# Connect to ChromaDB and create a collection for storing embeddings\n",
    "client = chromadb.Client()\n",
    "collection = client.create_collection(name=\"docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChromaDB is a vector database that allows you to store and query embeddings efficiently.\n",
    "\n",
    "The client.create_collection() method is used to create a new collection called docs where we will store our document embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Process Files and Store Embeddings in ChromaDB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"notes\"\n",
    "\n",
    "for file_name in os.listdir(data_folder):\n",
    "    file_path = os.path.join(data_folder, file_name)\n",
    "    if not os.path.isfile(file_path):  # Check if the file exists\n",
    "        print(f\"File not found: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Preprocess file to extract content\n",
    "        content = preprocess(file_path)\n",
    "        if content != \"Unsupported file type\":\n",
    "            # Get embeddings\n",
    "            response = ollama.embeddings(model=\"mxbai-embed-large\", prompt=content)\n",
    "            embedding = response[\"embedding\"]\n",
    "\n",
    "            # Add to ChromaDB collection\n",
    "            collection.add(\n",
    "                ids=[file_name],  # Use file name as ID\n",
    "                embeddings=[embedding],\n",
    "                documents=[content]\n",
    "            )\n",
    "            print(f\"Processed and stored embeddings for: {file_name}\")\n",
    "        else:\n",
    "            print(f\"Unsupported file type: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Query the database and generate responses\n",
    "Once the documents are processed and stored, you can query the database with a prompt. ChromaDB retrieves relevant documents, and Ollama generates a response based on the context of the retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    prompt = input(\"> \")\n",
    "\n",
    "    # Get the embedding for the query\n",
    "    response = ollama.embeddings(\n",
    "        prompt=prompt,\n",
    "        model=\"mxbai-embed-large\"\n",
    "    )\n",
    "\n",
    "    # Query the collection for similar documents\n",
    "    results = collection.query(\n",
    "        query_embeddings=[response[\"embedding\"]],\n",
    "        n_results=1  # Retrieve the most relevant document\n",
    "    )\n",
    "    \n",
    "    # Retrieve the document for the query\n",
    "    data = results['documents'][0][0]\n",
    "\n",
    "    # Generate a response using the retrieved document and the query\n",
    "    output = ollama.generate(\n",
    "        model=\"llama3.1\",\n",
    "        prompt=f\"Using this data: {data}. Respond to this prompt: {prompt}\"\n",
    "    )\n",
    "\n",
    "    # Print the response\n",
    "    print(output['response'])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
